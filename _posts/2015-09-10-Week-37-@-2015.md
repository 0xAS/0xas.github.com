---
layout : post
category : LearningNote
tags : [C++, Basis]
---

{% include JB/setup %}

- *2015.09.10*
    + 工作：一天都在重新配置mac的开发环境，还好最后参考了<a href="http://christopher5106.github.io/big/data/2015/07/16/deep-learning-install-caffe-cudnn-cuda-for-digits-python-on-mac-osx.html" target="blank">*link*</a>,完成了 *caffe*,*digits*和 *cudnn*的配置。成功跑了各种例程。
    + 生活： 今天教师节，祝贺爸妈姐姐节日快乐。一家四口有三口都在教育战线奋战。

- *2015.09.11*
    + 工作： ZNZ Symposium workshop
        * Jean-Pascal Pfister: 
            - computational task: generative model -> decoding model (learning)
            - mathematical formulation of the problem: 
                hidden process: $dX_t = f(X_t)dt + \sum^{1/2}_x dW_t$
                observation process: $dy_t = g(x_t)dt + \sum^{1/2}_ydv_t$

                Question: $p(x_t| y_{0...t})  = ?$

                What's the posterior distribution over the hidden causes $x_t$ given the post observations $y_{0...t}$
            - How can distribution be represented?
                + parametric way (probabilistic population code)
                + unweighted samples $p(x)~= N^{-1}\sum_j \theta(x-x^j)$
                + weighted samples (e.g. particle filter)
            - Algorithm: neural filter.
                + hidden process: $dx_t = f(x_t)dt + \sum^{1/2}_x dw_t$
                + observation process:
                + neural filter:
        * Michael Pfeiffer: what can machine learning learn from studying the brain?
            - he is mainly interestd in spike-based computation.
            - features of neuromorphic computing
                + massively parallel, asynchronous, event-driven (neuromorphic boards)
                + scaling up without slowing down (brain)
                + he talked about the event-based spike
                + he mentioned deep learning: deep learning is a net of lots of neurons, train it with certain way.
                + this is inspired by *hierarchical object recognition in ventral path*. deep learning aims to learn the intermediate representation of input sensory data.
                + principles of deep belief networks.
                + event-based deep belief networks. his paper in 2013
    + 